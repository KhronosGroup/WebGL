<?xml version="1.0" encoding="UTF-8"?>
<!-- vi:set sw=2 ts=4: -->
<proposal href="proposals/WEBGL_dynamic_texture/">
  <name>WEBGL_dynamic_texture</name>

  <contact><a href="https://www.khronos.org/webgl/public-mailing-list/">WebGL
  working group</a> (public_webgl 'at' khronos.org) </contact>

  <contributors>
    <contributor>Mark Callow</contributor>

    <contributor>Acorn Pooley</contributor>

    <contributor>Ken Russell</contributor>

    <contributor>David Sheets</contributor>

    <contributor>Members of the WebGL working group</contributor>
  </contributors>

  <number>NN</number>

  <depends>
    <api version="1.0"/>
  </depends>

  <overview id="overview">
    <p>A dynamic texture is a texture whose image changes frequently. The
    source of the stream of images may be a producer outside the control of
    the WebGL application. The classic example is using a playing video to
    texture geometry. Texturing with video is currently achieved by using the
    <code>TEXTURE2D</code> target and passing an <code>HTMLVideoElement</code>
    to <code>texImage2D</code>. It is difficult, if not impossible to
    implement video texturing with zero-copy efficiency via this API and much
    of the behavior is underspecified.</p>

    <p>This extension provides a mechanism for streaming image frames from an
    <code>HTMLVideoElement</code>, <code>HTMLCanvasElement</code> or
    <code>HTMLImageElement</code> (having multiple frames such those created
    from animated GIF, APNG and MNG files) into a WebGL texture. The extension
    defines a new texture target, <code>TEXTURE_EXTERNAL_OES</code> which can
    only be specified as being the consumer of an image stream from one of
    these elements.</p>

    <p>There is no support for most of the functions that manipulate other
    texture targets (e.g. you cannot use <code>*[Tt]ex*Image*()</code>
    functions with <code>TEXTURE_EXTERNAL_OES</code>). Also,
    <code>TEXTURE_EXTERNAL_OES</code> targets never have more than a single
    LOD level. These restrictions enable dynamic texturing with maximum
    efficiency. They remove the need for a copy of the image data manipulable
    via the WebGL API and allow sources which have internal formats not
    otherwise supported by WebGL, such as planar or interleaved YUV data, to
    be WebGL texture target siblings.</p>

    <p>The extension extends GLSL ES with a new
    <code>samplerExternalOES</code> type and matching sampling functions that
    provide a place for an implementation to inject code for sampling non-RGB
    data when necessary without degrading performance for other texture
    targets. Sampling a <code>TEXTURE_EXTERNAL_OES</code> via a sampler of
    type <code>samplerExternalOES</code> always returns RGBA data. This allows
    the implementation to decide the most efficient format to use whether it
    be RGB and or YUV data. If the underlying format was exposed, the
    application would have to query the format in use and provide shaders to
    handle both cases.</p>

    <p>The extension includes a mechanism for <em>latching</em> an image frame
    into a texture as its contents. This is equivalent to copying the image
    into the texture but, due to the restrictions outlined above a copy is not
    necessary. Most implementations will be able to avoid one so this can be
    much faster than using <code>texImage2D</code>. Latching can and should be
    implemented in a way that allows the producer to run independently of 3D
    rendering.</p>

    <mirrors href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt"
             name="NV_EGL_stream_consumer_external">
      <!-- list the deviations here if there are any -->

      <addendum>
        <p>An <code>HTMLVideoElement</code>, <code>HTMLCanvasElement</code> or
        <code>HTMLImageElement</code> is the producer and deliverer of the
        stream of images being consumed by the dynamic texture rather than the
        unspecified external producer and <code>EGLStream</code> pair referred
        to in the extension.</p>
      </addendum>

      <addendum>
        <p>References to <code>EGLImage</code> and associated state are
        deleted.</p>
      </addendum>

      <addendum>
        <p><code>dynamicTextureSetSource</code> is used to connect a texture
        to the image stream from an HTML element instead of the command
        <code>eglStreamConsumerGLTextureNV</code> or its equivalent
        <code>eglStreamConsumerGLTextureExternalKHR</code> referenced by the
        extension.</p>
      </addendum>

      <addendum>
        <p><code>dynamicTextureAcquireImage</code> and
        <code>dynamicTextureReleaseImage</code> are used to latch and unlatch
        image frames instead of the commands
        <code>eglStreamConsumerAcquireNV</code> or its equivalent
        <code>eglStreamConsumerAcquireKHR</code> and
        <code>eglStreamConsumerReleaseNV</code> or its equivalent
        <code>eglStreamConsumerReleaseKHR</code> referenced by the
        extension.</p>
      </addendum>

      <p>For ease of reading, this specification briefly describes the new
      functions and enumerants of <a
      href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt">NV_EGL_stream_consumer_external</a>.
      Consult that extension for detailed documentation of their meaning and
      behavior. Changes to the language of that extension are given <a
      href="#differences">later</a> in this specification.</p>
    </mirrors>

    <features>
      <feature>
        <p>The family of <code>dynamicTextureSetSource</code> functions for
        binding <code>HTML{Canvas,Image,Video}Elements</code> to a texture are
        available. </p>
      </feature>

      <feature>
        <p>The function <code>dynamicTextureGetSource</code> for querying the
        current dynamic source of a texture is available.</p>
      </feature>

      <feature>
        <p>The functions <code>dynamicTextureAcquireImage</code> and
        <code>dynamicTextureReleaseImage</code> are available. These commands
        are used before and after 3D rendering to latch an image that will not
        change during sampling.</p>
      </feature>

      <feature>
        <p>The functions <code>dynamicTextureSetConsumerLatencyUsec</code> and
        <code>dynamicTextureGetConsumerLatencyUsec</code> are available. These
        commands are used to inform a connected <code>HTMLVideoElement</code>
        of the latency between latching an image and displaying it and to
        query the currently set latency.</p>
      </feature>

      <glsl extname="WEBGL_dynamic_texture">
        <alias extname="NV_EGL_stream_consumer_external"/>

        <alias extname="OES_EGL_image_external"/>

        <stage type="fragment"/>

        <stage type="vertex"/>

        <type name="samplerExternalOES"/>

        <function name="texture2D" type="vec4">
          <param name="sampler" type="samplerExternalOES"/>

          <param name="coord" type="vec2"/>
        </function>

        <function name="texture2DProj" type="vec4">
          <param name="sampler" type="samplerExternalOES"/>

          <param name="coord" type="vec3"/>
        </function>

        <function name="texture2DProj" type="vec4">
          <param name="sampler" type="samplerExternalOES"/>

          <param name="coord" type="vec4"/>
        </function>
      </glsl>
    </features>
  </overview>

  <idl xml:space="preserve">module webgl {
  interface WEBGL_dynamic_texture {
    const GLenum TEXTURE_EXTERNAL_OES = 0x8D65;
    const GLenum SAMPLER_EXTERNAL_OES = 0x8D66;
    const GLenum TEXTURE_BINDING_EXTERNAL_OES = 0x8D67;
    const GLenum REQUIRED_TEXTURE_IMAGE_UNITS_OES = 0x8D68;

    void dynamicTextureSetSource(HTMLCanvasElement? source);
    void dynamicTextureSetSource(HTMLImageElement? source);
    void dynamicTextureSetSource(HTMLVideoElement? source);
    any dynamicTextureGetSource();
    void dynamicTextureAcquireImage();
    void dynamicTextureReleaseImage();
    void dynamicTextureSetConsumerLatencyUsec(HTMLVideoElement, int);
    int dynamicTextureGetConsumerLatencyUsec(HTMLVideoElement);
  }; // interface WEBGL_dynamic_texture
}; // module webgl </idl>

  <!-- new functions -->

  <newfun>
    <function name="dynamicTextureSetSource" type="void"><param name="source"
    type="HTMLCanvasElement?"/>Connects source <em>source</em> to the
    <code>WebGLTexture</code> that is bound to the
    <code>TEXTURE_EXTERNAL_OES</code> target of the active texture unit, as
    the producer of its image stream </function>

    <function name="dynamicTextureSetSource" type="void"><param name="source"
    type="HTMLImageElement?"/>Connects source <em>source</em> to
    the<code>WebGLTexture</code> that is bound to the
    <code>TEXTURE_EXTERNAL_OES</code> target of the active texture unit, as
    the producer of its image stream</function>

    <function name="dynamicTextureSetSource" type="void"><param name="source"
    type="HTMLVideoElement?"/>Connects source <em>source</em> to
    <code>WebGLTexture texture</code> that is bound to the
    <code>TEXTURE_EXTERNAL_OES</code> target of the active texture unit, as
    the producer of its image stream</function>

    <function name="dynamicTextureGetSource" type="any">Returns the
    <code>HTML{Canvas,Image,Video}Element</code> that is connected as a source
    of images to the <code>WebGLTexture</code> bound to the
    <code>TEXTURE_EXTERNAL_OES</code> target of the active texture
    unit.</function>

    <function name="dynamicTextureAcquireImage" type="void">Causes the
    <code>WebGLTexture</code> bound to the
    <code>TEXTURE_EXTERNAL_OES</code>target of the active texture unit to
    acquire an image frame from the producer connected to it . The image data
    is guaranteed not to change during sampling.</function>

    <function name="dynamicTextureReleaseImage" type="void">Causes the
    <code>WebGLTexture</code> bound to the
    <code>TEXTURE_EXTERNAL_OES</code>target of the active texture unit to
    release an acquired image frame back to the buffer pool available to the
    producer connected to it. After this sampling will return
    (0,0,0,1).</function>

    <function name="dynamicTextureSetConsumerLatencyUsec" type="void"><param
    name="source" type="HTMLVideoElement"/><param name="latency"
    type="int"/>Informs an HTMLVideo source the average latency between
    latching an image and displaying it. Setting the latency enables the
    HTMLVideoElement to make necessary adjustments to keep audio in
    sync.</function>

    <function name="dynamicTextureSetConsumerLatencyUsec" type="int">Returns
    the currently set latency.</function>
  </newfun>

  <!-- new tokens -->

  <newtok>
    <p>The meaning and use of these tokens is exactly as described in <a
    href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt">NV_EGL_stream_consumer_external</a>.</p>

    <function name="bindTexture" type="void"><param name="target"
    type="GLenum"/><param name="texture"
    type="WebGLTexture?"/><code>TEXTURE_EXTERNAL_OES</code> is accepted as a
    target by the <code>target</code> parameter of
    <code>bindTexture()</code></function>

    <function name="getActiveUniform" type="WebGLActiveInfo?"><param
    name="program" type="WebGLProgram?"/><param name="index"
    type="GLuint"/><code>SAMPLER_EXTERNAL_OES</code> can be returned in the
    <code>type</code> field of the <code>WebGLActiveInfo</code> returned by
    <code>getActiveUniform()</code></function>

    <function name="getParameter" type="any"><param name="pname"
    type="GLenum"/><code>TEXTURE_BINDING_EXTERNAL_OES</code> is accepted by
    the <code>pname</code> parameter of
    <code>getParameter()</code>.</function>

    <function name="getTexParameter*" type="any"><param name="target"
    type="GLenum"/><param name="pname"
    type="GLenum"/><code>REQUIRED_TEXTURE_IMAGE_UNITS_OES</code> is accepted
    as the <code>pname</code> parameter of
    <code>GetTexParameter*()</code></function>
  </newtok>

  <!-- Refer to the <http://www.opengl.org/registry/doc/template.txt> OpenGL
       extension template for a description of these sections. These sections
       should be eliminated for WebGL extensions simply mirroring OpenGL or
       OpenGL ES extensions.
  -->

  <!-- these take XHTML markup as contents -->

  <security/>

  <ipstatus>No known IP claims.</ipstatus>

  <newtypes/>

  <additions>
    <!-- Additions to Chapters of the WebGL Specification-->

    <p>In section 4.3 <cite>Supported GLSL Constructs</cite>, replace the
    paragraph beginning <cite>A WebGL implementation must ...</cite> with the
    following paragraph:<blockquote>A WebGL implementation must only accept
    shaders which conform to The OpenGL ES Shading Language, Version 1.00 <a
    href="https://www.khronos.org/registry/webgl/specs/1.0/#refsGLES20GLSL">[GLES20GLSL]</a>,
    as extended by <a
    href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt">NV_EGL_stream_consumer_external</a>,
    and which do not exceed the minimum functionality mandated in Sections 4
    and 5 of Appendix A. In particular, a shader referencing state variables
    or commands that are available in other versions of GLSL (such as that
    found in versions of OpenGL for the desktop), must not be allowed to
    load.</blockquote></p>

    <p>In section 5.13 <cite>The WebGL Context</cite> , add the following to
    the WebGLRenderingContext interface. Note that until such time as this
    extension enters core WebGL the tokens and commands mentioned below will
    be located on the WebGL_dynamic_texture extension interface shown
    above.<li>In the list following <code>/* GetPName */</code>:<pre
    class="idl" xml:space="preserve">TEXTURE_BINDING_EXTERNAL = 0x8D67;</pre></li><li>In
    the list following <code>/* TextureParameterName */</code>:<pre
    class="idl" xml:space="preserve">REQUIRED_TEXTURE_IMAGE_UNITS = 0x8D68;</pre></li><li>In
    the list following <code>/* TextureTarget */</code>:<pre class="idl"
    xml:space="preserve">TEXTURE_EXTERNAL = 0x8D65;</pre></li><li>In the list
    following <code>/* Uniform Types */</code>:<pre class="idl"
    xml:space="preserve">SAMPLER_EXTERNAL = 0x8D66;</pre></li><li>In the
    alphabetical list of commands add the following :<pre class="idl"
    xml:space="preserve">void dynamicTextureAcquireImage();
int dynamicTextureGetConsumerLatencyUsec();
any dynamicTextureGetSource();
void dynamicTextureReleaseImage();
void dynamicTextureSetConsumerLatencyUsec(HTMLVideoElement);
void dynamicTextureSetSource(HTMLCanvasElement? source);
void dynamicTextureSetSource(HTMLImageElement? source);
void dynamicTextureSetSource(HTMLVideoElement? source);</pre></li></p>

    <p>In section 5.13.3 <cite>Setting and getting state</cite>, add the
    following to the table under <code>getParameter</code>.</p>

    <dl class="methods">
      <dt class="idl-code">
        <dd>
          <table>
            <tr>
              <td>TEXTURE_BINDING_EXTERNAL</td>

              <td>int</td>
            </tr>
          </table>
        </dd>
      </dt>
    </dl>

    <p/>

    <p>In section 5.13.8<cite>Texture objects</cite>, add the following to the
    table under <code>getTexParameter</code>.</p>

    <dl class="methods">
      <dt class="idl-code">
        <dd>
          <table>
            <tr>
              <td>REQUIRED_TEXTURE_IMAGE_UNITS</td>

              <td>int</td>
            </tr>
          </table>
        </dd>
      </dt>
    </dl>

    <p/>

    <p>Add a new section 5.13.8.1 Dynamic textures.</p>

    <blockquote>
      <h3>5.13.8.1 Dynamic textures</h3>

      <p>Dynamic textures are texture objects whose complete image data
      changes frequently. The source of the stream of images may be a producer
      outside the control of the WebGL application. The classic example is
      using a playing video to texture geometry. A dynamic texture object is
      created by binding an unused <code>WebGLTexture</code> to the target
      <code>TEXTURE_EXTERNAL_OES</code>. Note that only unused WebGLTextures
      or those previously used as dynamic textures can be bound to
      <code>TEXTURE_EXTERNAL_OES</code>. Binding a <code>WebGLTexture</code>
      previously used with a different target or binding a WebGLTexture
      previously used with TEXTURE_EXTERNAL_OES to a different target
      generates a <code>GL_INVALID_OPERATION</code> error as documented in <a
      href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt">GL_NV_EGL_stream_consumer_external.txt</a>.</p>

      <p>The commands<pre class="idl" xml:space="preserve">void dynamicTextureSetSource(HTMLCanvasElement? source);
void dynamicTextureSetSource(HTMLImageElement? source);
void dynamicTextureSetSource(HTMLVideoElement? source);</pre>connect the
      texture object currently bound to the <code>TEXTURE_EXTERNAL_OES</code>
      target in the active texture unit as the consumer of the stream of
      images produced by the HTMLElement <em>source</em>. If <em>source</em>
      is null any previously connected producer is removed.</p>

      <p>If <em>source</em> is an HTMLCanvasElement object with either a
      horizontal dimension or a vertical dimension equal to zero, then the
      implementation must throw an InvalidStateError exception. <em>XXX
      Mirrors CanvasRenderingContext2D.drawImage. Do we need to do
      this?</em></p>

      <p>The command<pre class="idl" xml:space="preserve">any? dynamicTextureGetSource(WebGLTexture texture, HTMLCanvasElement? source);</pre>returns
      a handle to the currently connected image source.</p>

      <p>The command<pre class="idl" xml:space="preserve">void dynamicTextureAcquireImage();</pre>causes
      the texture object currently bound to the
      <code>TEXTURE_EXTERNAL_OES</code> target in the active texture unit to
      <em>latch</em> the most recent image frame from its currently connected
      source. The rules for selecting the image to be latched mirror those for
      selecting the image drawn by the <code>drawImage</code> method of <a
      href="http://www.whatwg.org/specs/web-apps/current-work/multipage/the-canvas-element.html#canvasrenderingcontext2d">CanvasRenderingContext2D</a>.</p>

      <p>For HTMLVideoElements, it will latch the frame at the <a
      href="http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#current-playback-position">current
      playback position</a>, as defined in the <a
      href="http://www.whatwg.org/specs/web-apps/current-work/">HTML Living
      Standard</a>, unless the element's readyState attribute is either
      HAVE_NOTHING or HAVE_METADATA, in which case the command returns without
      latching anything and the texture remains <em>incomplete</em>.</p>

      <p>For animated HTMLImageElements it will latch the first frame of the
      animation.</p>

      <p>For HTMLCanvasElements it will latch the current content of the
      canvas as would be returned by a call to <code>toDataURL</code>.</p>

      <p>The model is a stream of images between the producer and the
      WebGLTexture consumer. <code>dynamicTextureAcquireImage</code> latches
      the most recent image frame. If the producer has not inserted any new
      image frames since the last call to
      <code>dynamicTextureAcquireImage</code> then
      <code>dynamicTextureAcquireImage</code> will latch the same image frame
      it latched last time it was called. If the producer has inserted one new
      image frame since the last call then
      <code>dynamicTextureAcquireImage</code> will "latch" the newly inserted
      image frame. If the producer has inserted more than one new image frame
      since the last call then all but the most recently inserted image frames
      are discarded and <code>dynamicTextureAcquireImage</code> will "latch"
      the most recently inserted image frame. For HTMLVideoElements, the
      application can use the value of the <code>currentTime</code> attribute
      to identify which image frame was actually latched.</p>

      <p>The command <pre class="idl" xml:space="preserve">void dynamicTextureReleaseImage(WebGLTexture texture);</pre>releases
      the latched image. <code>dynamicTextureReleaseImage</code> will prevent
      the producer from re-using and/or modifying the image frame until all
      preceding WebGL commands that use the image frame as a texture have
      completed. If <code>dynamicTextureAcquireImage</code> is called twice
      for the same texture and producer pair without an intervening call to
      <code>dynamicTextureReleaseImage</code> then dynamicTextureReleaseImage
      is implicitly called at the start of
      <code>dynamicTextureAcquireImage</code>.</p>

      <p>After successfully calling <code>dynamicTextureReleaseImage</code>
      the texture becomes "incomplete".</p>

      <p>If <code>dynamicTextureReleaseImage</code> is called twice without a
      successful intervening call to <code>dynamicTextureAcquireImage</code>,
      or called with no previous call to
      <code>dynamicTextureAcquireImage</code>, then the call does nothing and
      the texture remains in "incomplete" state. This is not an error.</p>

      <p><code>dynamicTextureAcquireImage</code> and
      <code>dynamicTextureReleaseImage</code> generate an INVALID_OPERATION
      error if no dynamic source is bound to the texture.</p>

      <p>The command <pre class="idl" xml:space="preserve">void dynamicTextureSetConsumerLatencyUsec(HTMLVideoElement source, int latency);</pre>informs
      the <em>source</em> <code>HTMLVideoElement</code> that the time that
      elapses (on average) from when the application latches an image frame
      with <code>dynamicTextureAcquireImage</code> until the image frame is
      visible to the user is <em>latency</em> microseconds. The initial value
      is an implementation-dependent constant value, possibly zero.
      Applications are encouraged to adjust this value dynamically as
      conditions change. Applications may also modify this value to adjust the
      timing of the stream under direction from a user, e.g., to make video
      frames coincide with an audio track. The <code>HTMLVideoElement</code>
      should use this information to deliver frames at an appropriate time.
      The producer should deliver each image frame into the stream at the time
      that frame should appear to the user MINUS the <em>latency</em>and it
      should adjust the latency of audio and other synchronized tracks to
      match.</p>

      <p>The command<pre class="idl" xml:space="preserve">int dynamicTextureGetConsumerLatencyUsec(HTMLVideoElement source);</pre>returns
      the current value of the latency set by the application.</p>

      <p>To sample a dynamic texture, the texture object must be bound to the
      target <code>TEXTURE_EXTERNAL</code> and the sampler uniform must be of
      type <code>samplerExternal</code>. If the texture object bound to
      <code>TEXTURE_EXTERNAL</code> is not bound to a dynamic source then the
      texture is "incomplete" and the sampler will return the RGBA value
      (0,0,0,1).</p>
    </blockquote>

    <p>In section 5.13.10 <cite>Uniforms and attributes</cite>, add the
    following to the table under <code>getUniform</code>.</p>

    <dl class="methods">
      <dt class="idl-code">
        <dd>
          <table>
            <tr>
              <td>samplerExternal</td>

              <td>long</td>
            </tr>
          </table>
        </dd>
      </dt>
    </dl>

    <p/>

    <p><a id="differences"/>At the end of section 6 <cite>Differences between
    WebGL and OpenGL ES</cite>, add the following new sections. Note that
    differences are considered with respect to the OpenGL ES 2.0 specification
    as extended by <a
    href="https://cvs.khronos.org/svn/repos/registry/trunk/public/gles/extensions/NV/GL_NV_EGL_stream_consumer_external.txt">NV_EGL_stream_consumer_external</a>
    in the absence of <a
    href="http://www.khronos.org/registry/gles/extensions/OES/OES_EGL_image_external.txt">OES_EGL_image_external</a>.</p>

    <blockquote>
      <h3>External Texture Support</h3>

      <p>WebGL supports <em>external textures</em> but has no notion of an
      <code>EGLStream</code>. The source of images for an external texture is
      the HTMLCanvasElement, HTMLImageElement or HTMLVideoElement which has
      been connected to it with <code>dynamicTextureSetSource</code>
      (<em>dynamic HTML element</em>). Specific language changes follow.</p>

      <p>In section <cite>3.7.14 External Textures</cite> the sentence in the
      penultimate paragraph beginning <cite>The parameters of the
      transformation ...</cite> is replaced with<blockquote>
          <p>The parameters of the transformation from one basis (e.g. YUV) to
          RGB (color conversion matrix, sampling offsets, etc) are taken from
          the source of the dynamic HTML element that is associated with the
          external texture.</p>
        </blockquote></p>

      <p>The final paragraph is replaced with<blockquote>
          <p>If the image frames in the dynamic HTML element contain alpha
          values then the value of the alpha component returned is taken from
          the image; otherwise the alpha component is 1.0.</p>
        </blockquote></p>

      <p>Section <cite>3.7.14.1 External Textures as Stream Consumers</cite>
      is replaced with the following.<blockquote>
          <p>To use a TEXTURE_EXTERNAL_OES texture as the consumer of images
          from a dynamic HTML element, bind the texture to the active texture
          unit, and call <code>dynamicTextureSetSource</code>. The width,
          height, format, type, internalformat, border and image data of the
          TEXTURE_EXTERNAL_OES texture will all be determined based on the
          specified dynamic HTML element. If the element does not have any
          source or the source is not yet loaded, the width, height &amp;
          border will be zero, the format and internal format will be
          undefined. Once the element's source has been loaded and one (or
          more) images have been decoded these attributes are determined
          (internally by the implementation), but they are not exposed to the
          WebGL application and there is no way to query their values.</p>

          <p> The TEXTURE_EXTERNAL_OES texture remains the consumer of the
          dynamic HTML element's image frames until the first of any of these
          events occur:<ol>
              <li>The texture is associated with a different dynamic HTML
              element (with a later call to
              <code>dynamicTextureSetSource</code>).</li>

              <li>The texture is deleted in a call to
              <code>deleteTextures</code>.</li>
            </ol></p>

          <p>Sampling an external texture which is not connected to a dynamic
          HTML element will return a sample value of (0,0,0,1). Sampling an
          external texture which is connected to a dynamic HTML element will
          return a sample value of (0,0,0,1) unless an image frame has been
          'latched' into the texture by a successful call to
          dynamicTextureAcquireImage.</p>
        </blockquote></p>
    </blockquote>
  </additions>

  <errors/>

  <newstate/>

  <newimplstate/>

  <!-- New Implementation-Dependent State -->

  <samplecode>
    <div class="example">This a fragment shader that samples a video texture.
    Note that the surrounding <code>&lt;script&gt;</code> tag is not
    essential; it is merely one way to include shader text in an HTML
    file.<pre xml:space="preserve">&lt;script id="fshader" type="x-shader/x-fragment"&gt;
  #extension OES_EGL_image_external : enable 
  precision mediump float;

  uniform samplerExternalOES videoSampler;

  varying float v_Dot;
  varying vec2 v_texCoord;

  void main()
  {
    vec2 texCoord = vec2(v_texCoord.s, 1.0 - v_texCoord.t);
    vec4 color = texture2D(videoSampler, texCoord);
    color += vec4(0.1, 0.1, 0.1, 1);
    gl_FragColor = vec4(color.xyz * v_Dot, color.a);
  }
&lt;/script&gt;</pre></div>

    <div class="example">This shows fragments from an application that renders
    a spinning cube textured with a live video.<pre xml:space="preserve">&lt;html&gt;
&lt;script type="text/javascript"&gt;

  ///////////////////////////////////////////////////////////////////////
  // Create a video texture and bind a source to it.
  ///////////////////////////////////////////////////////////////////////

  // Array of files currently loading
  g_loadingFiles = [];

  // Clears all the files currently loading.
  // This is used to handle context lost events.
  function clearLoadingFiles() {
    for (var ii = 0; ii &lt; g_loadingFiles.length; ++ii) {
      g_loadingFiles[ii].onload = undefined;
    }
    g_loadingFiles = [];
  }

  //
  // createVideoTexture
  //
  // Load video from the passed HTMLVideoElement id, bind it to a new WebGLTexture object
  // and return the WebGLTexture.
  //
  // Is their a constructor for an HTMLVideoElement so you can do like "new Image()?"
  //
  function createVideoTexture(ctx, videoId)
  {
    var texture = ctx.createTexture();
    var video = document.getElementById(videoId);
    g_loadingFiles.push(video);
    video.onload = function() { doBindVideo(ctx, video, texture) }
    return texture;
  }

  function doBindVideo(ctx, video, texture)
  {
    g_loadingFiles.splice(g_loadingFiles.indexOf(image), 1);
    ctx.bindTexture(ctx.TEXTURE_EXTERNAL_OES, texture);
    ctx.dynamicTextureSetSource(video);
    // These are the default values of these properties so the following
    // 4 lines are not necessary.
    ctx.texParameteri(ctx.TEXTURE_EXTERNAL_OES, ctx.TEXTURE_MAG_FILTER, ctx.LINEAR);
    ctx.texParameteri(ctx.TEXTURE_EXTERNAL_OES, ctx.TEXTURE_MIN_FILTER, ctx.LINEAR);
    ctx.texParameteri(ctx.TEXTURE_EXTERNAL_OES, ctx.TEXTURE_WRAP_S, ctx.CLAMP_TO_EDGE);
    ctx.texParameteri(ctx.TEXTURE_EXTERNAL_OES, ctx.TEXTURE_WRAP_T, ctx.CLAMP_TO_EDGE);
    ctx.bindTexture(ctx.TEXTURE_EXTERNAL_OES, null);
  }

  ///////////////////////////////////////////////////////////////////////
  // Initialize the application.
  ///////////////////////////////////////////////////////////////////////

  var g = {};
  var videoTexture;

  function init()
  {
    // Initialize
    var gl = initWebGL(
        // The id of the Canvas Element
        "example");
    if (!gl) {
      return;
    }
    var program = simpleSetup(
        gl,
        // The ids of the vertex and fragment shaders
        "vshader", "fshader",
        // The vertex attribute names used by the shaders.
        // The order they appear here corresponds to their index
        // used later.
        [ "vNormal", "vColor", "vPosition"],
        // The clear color and depth values
        [ 0, 0, 0.5, 1 ], 10000);

    // Set some uniform variables for the shaders
    gl.uniform3f(gl.getUniformLocation(program, "lightDir"), 0, 0, 1);
    // Use the default texture unit 0 for the video
    gl.uniform1i(gl.getUniformLocation(program, "samplerExternal"), 0);

    // Create a box. On return 'gl' contains a 'box' property with
    // the BufferObjects containing the arrays for vertices,
    // normals, texture coords, and indices.
    g.box = makeBox(gl);

    // Load an image to use. Returns a WebGLTexture object
    videoTexture = createVideoTexture(gl, "video");
    // Bind the video texture
    gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, videoTexture);

    // Create some matrices to use later and save their locations in the shaders
    g.mvMatrix = new J3DIMatrix4();
    g.u_normalMatrixLoc = gl.getUniformLocation(program, "u_normalMatrix");
    g.normalMatrix = new J3DIMatrix4();
    g.u_modelViewProjMatrixLoc =
            gl.getUniformLocation(program, "u_modelViewProjMatrix");
    g.mvpMatrix = new J3DIMatrix4();

    // Enable all of the vertex attribute arrays.
    gl.enableVertexAttribArray(0);
    gl.enableVertexAttribArray(1);
    gl.enableVertexAttribArray(2);

    // Set up all the vertex attributes for vertices, normals and texCoords
    gl.bindBuffer(gl.ARRAY_BUFFER, g.box.vertexObject);
    gl.vertexAttribPointer(2, 3, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ARRAY_BUFFER, g.box.normalObject);
    gl.vertexAttribPointer(0, 3, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ARRAY_BUFFER, g.box.texCoordObject);
    gl.vertexAttribPointer(1, 2, gl.FLOAT, false, 0, 0);

    // Bind the index array
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, g.box.indexObject);

    return gl;
  }

  // ...

  ///////////////////////////////////////////////////////////////////////
  // Draw a frame
  ///////////////////////////////////////////////////////////////////////
  function draw(gl)
  {
    // Make sure the canvas is sized correctly.
    reshape(gl);

    // Clear the canvas
    gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

    // Make a model/view matrix.
    g.mvMatrix.makeIdentity();
    g.mvMatrix.rotate(20, 1,0,0);
    g.mvMatrix.rotate(currentAngle, 0,1,0);

    // Construct the normal matrix from the model-view matrix and pass it in
    g.normalMatrix.load(g.mvMatrix);
    g.normalMatrix.invert();
    g.normalMatrix.transpose();
    g.normalMatrix.setUniform(gl, g.u_normalMatrixLoc, false);

    // Construct the model-view * projection matrix and pass it in
    g.mvpMatrix.load(g.perspectiveMatrix);
    g.mvpMatrix.multiply(g.mvMatrix);
    g.mvpMatrix.setUniform(gl, g.u_modelViewProjMatrixLoc, false);

    // Acquire the latest video image
    gl.dynamicTextureAcquireImage();

    // Draw the cube
    gl.drawElements(gl.TRIANGLES, g.box.numIndices, gl.UNSIGNED_BYTE, 0);

    // Allow updates to the image again
    gl.dynamicTextureReleaseImage();

    // Show the framerate
    framerate.snapshot();

    currentAngle += incAngle;
    if (currentAngle &gt; 360)
      currentAngle -= 360;
  }
&lt;/script&gt;

&lt;body onload="start()"&gt;
&lt;video id="video" src="resources/video.ogv" autoplay="true" style="visibility: hidden"&gt;
&lt;/video&gt;
&lt;canvas id="example"&gt;
    If you're seeing this your web browser doesn't support the &amp;lt;canvas&amp;gt; element. Ouch!
&lt;/canvas&gt;
&lt;div id="framerate"&gt;&lt;/div&gt;
&lt;/body&gt;

&lt;/html&gt;</pre></div>
  </samplecode>

  <tests/>

  <issues>
    <ol>
      <li>
        <p>Why not use the <code>TEXTURE2D</code> target and
        <code>texImage2D</code>?</p>

        <p>RESOLVED: Use a new texture target and new commands. A new texture
        target makes it easy to specify, implement and conformance test the
        restrictions that enable a zero-copy implementation of dynamic
        textures as described in the <a href="#overview">Overview</a>. Given
        that one of those restriction is not allowing modification of the
        texture data, which is normally done via <code>texImage2D</code> using
        a new command will make the usage model clearer.</p>
      </li>

      <li>
        <p>Why not use sampler2D uniforms?</p>

        <p>RESOLVED: Use a new sampler type. Most zero-copy implementations
        will need special shader code when sampling a YUV format dynamic
        textures. Implementations may choose to (a) re-compile at run time or
        (b) inject conditional code which branches at run time according to
        the format of the texture bound to TEXTURE_EXTERNAL_OES in the texture
        unit to which the sampler variable is set. Without a new sampler type,
        such conditional code would have to be injected for every sampler
        fetch increasing the size of the shader and slowing sampling of other
        texture targets. In order to preserve the possibility of using
        approach (b), a new sampler type will be used.</p>
      </li>

      <li>
        <p>Should the API be implemented as methods on the texture object or
        commands taking a texture object as a parameter?</p>

        <p>RESOLVED: Neither. The <code>WebGLTexture</code> object represents
        an OpenGL texture name. No object is created until the name is bound
        to a texture target. Therefore the new commands should operate on a
        the currently bound texture object.</p>
      </li>

      <li>
        <p>Should dynamic textures be a new texture type or can
        <code>WebGLTexture</code> be reused?</p>

        <p>RESOLVED: Do not use a new texture type. As noted in the previous
        issue a <code>WebGLTexture</code> represents a texture name and is a
        handle to multiple texture types. The type of texture is set according
        to the target to which the name is initially bound.</p>
      </li>

      <li>
        <p>Should we re-use <code>#extension
        NV_EGL_stream_consumer_external</code>, create our own GLSL extension
        name or have both this and a WebGL-specific name?</p>

        <p>RESOLVED: Any of <code>WEBGL_dynamic_texture</code> or the aliases
        <code>NV_EGL_stream_consumer_external</code> or
        <code>OES_EGL_image_external</code> can be used to enable this
        extension's features in the shader. This permits the same shader to be
        used with both WebGL and OpenGL ES 2.0.</p>
      </li>

      <li>
        <p>What should happen when an object of type
        <code>HTMLCanvasElement</code>, <code>HTMLImageElement</code> or
        <code>HTMLVideoElement</code>is passed to the existing
        <code>tex*Image2D</code> commands?</p>

        <p>UNRESOLVED: Suggestion: for single-frame HTMLImageElement set the
        texture image to the HTMLImageElement; for an animated
        HTMLImageElement set the texture image to the first frame of the
        animation; for an HTMLCanvasElement, set the texture image to the
        current canvas image that would be returned by toDataURL; for an
        HTMLVideoElement, set the texture image to the current frame. In all
        cases, the texture image does not change until a subsequent call to a
        <code>tex*Image2D</code> command. <em>Is this a change from the way
        any of these elements are handled today? This area is very
        underspecified and needs to be clarified in the WebGL
        specification.</em></p>
      </li>

      <li>
        <p>Should <code>dynamicTextureAcquireImage</code> and
        <code>dynamicTextureReleaseImage</code> generate errors if called when
        the image is already in the state to be set or ignore those extra
        calls?</p>

        <p>RESOLVED: They should not generate errors.
        <code>dynamicTextureAcquireImage</code> will be defined to implicitly
        call <code>dynamicTextureReleaseImage</code> if there has not been an
        intervening call.</p>
      </li>

      <li>
        <p>This API is implementable on any platform at varying levels of
        efficiency. Should it therefore move directly to core rather than
        being an extension?</p>

        <p>UNRESOLVED:</p>
      </li>

      <li>
        <p>Should this extension use direct texture access commands or should
        it use <code>texParameter</code> and <code>getTexParameter</code>?</p>

        <p>RESOLVED: If direct texture access commands are used several new
        interactions and errors will have to be specified because the
        <code>WebGLTexture</code> does not always represent an object that can
        be connected to a source of image frames.<code>texParameter</code>
        doesn't seem unreasonable for binding the dynamic source but doesn't
        feel right for acquireImage and releaseImage as that operation has
        nothing to do with texture parameters. Therefore those commands will
        will operate on the texture object bound to a new target. For
        othogonality so too will setSource.</p>
      </li>

      <li>
        <p>Should this extension support HTMLImageElement?</p>

        <p>UNRESOLVED: If we are tracking the behavior of
        CanvasRenderingContext2D.drawImage then there is no point supporting
        HTMLImageElement. The HTML5 specification for <a>canvas</a>says for
        animated images to draw the first frame.</p>
      </li>

      <li>
        <p>Should this extension extend <code>HTMLMediaElement</code> with an
        acquireImage/releaseImage API?</p>

        <p>RESOLVED: No. The API would have no purpose and would require
        HTML{Video,Canvas,Image}Element becoming aware of WebGLTexture or,
        even worse, aware of texture binding within WebGL. No similar API was
        exposed to support CanvasRenderingContext2D.drawImage. The HTMLElement
        is simply passed to drawImage.</p>
      </li>
    </ol>
  </issues>

  <history>
    <revision date="2012/07/05">
      <change>Initial revision.</change>
    </revision>

    <revision date="2012/07/06">
      <change>Fixed incorrect dependency and minor naming inconsistencies.
      Fixed missing parameter error and moved the location of the bindTexture
      call in the sample code.</change>
    </revision>

    <revision date="2012/07/20">
      <change>Significant rewrite that bases the extension on
      GL_NV_EGL_stream_consumer_external and which uses semantics and
      concepts" from EGLStream rather than EGLImage.</change>
    </revision>
  </history>
</proposal>
